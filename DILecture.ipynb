{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock Lecture: Hypothesis Testing / Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivating Example\n",
    "\n",
    "Consider the following scenario: \n",
    "\n",
    "Maia just accepted a new job offer, but she really hates commuting.  A lot.  She appreciates that her commute time will fluctuate from day to day based on weather, traffic, and other random factors, but she is absolute in her refusal to continue working at any job for which her average commute time is greater than 30 minutes.  \n",
    "\n",
    "In the given scenario, the main hypothesis Maia will wish to test is whether, after having gone to work for some number of days and observing her commute times on each day, her expected commute time is greater than 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Components of a Hypothesis Test\n",
    "\n",
    "Every hypothesis test relies on three parts:  \n",
    "\n",
    "1. A model\n",
    "1. A null hypothesis \n",
    "1. An alternative hypothesis \n",
    "\n",
    "### Part 1: A Model\n",
    "\n",
    "Before we can even posit a hypothesis to test, we first need to specify a *model*.  At the most basic level, a model consists of a set of assumptions about how the data we will use to test our hypotheses were generated and, in particular, makes some specific statements about the form(s) of randomness that appear in these data.  A very simple model that we could posit in our current example is that Maia's commute time each day is an identically and independently distributed (i.i.d) Gaussian random variable \n",
    "\n",
    "$X \\overset{i.i.d.}{\\sim}N(\\mu,\\sigma^2)$ \n",
    "\n",
    "In the analysis that follows, it will be useful to write $X$ in mean-error form \n",
    "\n",
    "$X = \\mu + \\varepsilon$, \n",
    "\n",
    "where $ \\varepsilon \\overset{i.i.d.}{\\sim} N(0,\\sigma^2)$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: A null hypothesis\n",
    "\n",
    "The second necessary component Maia needs to conduct her test is a *null hypothesis*.  A null hypothesis is a restriction of one or more of the parameters of the model.  \n",
    "\n",
    "Our current model, $X \\overset{i.i.d.}{\\sim}N(\\mu,\\sigma^2)$, has two parameters: $\\mu$, the expected commute time and $\\sigma^2$, the population variance of commute time.  \n",
    "\n",
    "For Maia's problem, the appropriate null hypothesis for her to use is \n",
    "\n",
    "$H_0: \\mu = 30$.  \n",
    "\n",
    "You might have two questions in your head at this point:\n",
    "\n",
    "1. Why did Maia choose $\\mu = 30$ as her null hypothesis rather than $\\mu=25$ or $\\mu=35$?\n",
    "1. Why does Maia's null hypothesis restrict $\\mu$ but not $\\sigma^2$?\n",
    "\n",
    "We'll return to these questions later.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: An alternative hypothesis\n",
    "\n",
    "The final necessary component Maia needs is an *alternative hypothesis*.  The alternative hypothesis describes what Maia actually hopes to learn from conducting her test.  Since she's conducting this test to determine whether she should stay at her current workplace, the appropriate alternative hypothesis for her to test is \n",
    "\n",
    "$H_a$: $\\mu > 30$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a hypothesis test?\n",
    "\n",
    "After commuting to work for some number $n$ days, Maia has accumulated a sample of commute times $\\{x_i\\}_{i=1}^{n}$ that she can use to conduct a *hypothesis test*.  \n",
    "\n",
    "One can think of a hypothesis test as an answer to the following hypothetical question:\n",
    "\n",
    "If the null hypothesis $H_0$ were true, what is the probability that, if I drew another sample equal in size to the one I have, it would look at least as odd (in a sense that will vary based on context) as the sample I have?  \n",
    "\n",
    "\n",
    "\n",
    "In Maia's scenario, we want to estimate the probability that, if Maia's model and null hypothesis are both correct, that her mean commuting time over the *next* $n$ days will be at least as large as it was over the first $n$ days.  \n",
    "\n",
    "* If this probability is very small, there is a high likelihood that either the null hypothesis or the model is wrong and Maia should quit (Maia rejects the null hypothesis).\n",
    "* If this probability is not very small, Maia cannot say with great certainty that her expected commute time is greater than 30 minutes (Maia fails to reject the null hypothesis).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Deriving an appropriate test (Part I) \n",
    "\n",
    "\n",
    "Her model determines the appropriate test she should use.  Since she's trying to learn about her true (population) mean commute time, $\\mu$, a natural starting point for deriving a test statistic is to look at the mean commute time in her sample: \n",
    "\n",
    "$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$\n",
    "\n",
    "Under the model, the distribution of $\\bar{x}$ can be derived as\n",
    "\n",
    "$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$\n",
    "\n",
    "$\\bar{x}= \\frac{1}{n}\\sum_{i=1}^{n} \\mu + \\varepsilon_i$ \n",
    "\n",
    "$\\bar{x} - \\mu  = \\frac{1}{n}\\sum_{i=1}^{n} \\varepsilon_i$ \n",
    "\n",
    "Since each $\\varepsilon_i \\overset{i.i.d.}{\\sim} N(0,\\sigma^2)$, the distribution of the entire summation term in the above expression a Gaussian random variable with distribution \n",
    "\n",
    "$\\sum_{i=1}^{n} \\varepsilon_i \\sim N(0, n \\sigma^2)$\n",
    "\n",
    "which implies that \n",
    "\n",
    "$ \\frac{\\sqrt{n}(\\bar{x} - \\mu)}{\\sigma} \\sim N(0,1)$ \n",
    "\n",
    "If Maia's null hypothesis made assumptions about both $\\mu$ and $\\sigma^2$, the above expression would allow us to compute the probability of observing a mean at least as large as her sample mean.  Otherwise, we need to keep working.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Deriving an appropriate test (Part II) \n",
    "\n",
    "Since our null hypothesis doesn't specify the value of $sigma^2$ to use in our test, Maia needs to use her sample to estimate it and factor in the additional uncertainty that results from not knowing it into her testing procedure.  The following results facilitate this\n",
    "\n",
    "1. $s^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2$ is an unbiased estimator of $\\sigma^2$  <a href=\"#proof1\">Proof</a>\n",
    "\n",
    "1. $\\frac{s^2}{(n-1)\\sigma^2}\\sim \\chi^2(n-1)$ <a href=\"#proof2\">Proof</a>\n",
    "    \n",
    "1. $\\frac{s^2}{\\sigma^2}$ and $\\bar{x} - \\mu$ are independent <a href=\"#proof2\">Proof</a>\n",
    "\n",
    "Based on these results, $\\frac{\\sqrt{n}(\\bar{x}-\\mu)}{s}$ is t-distributed with $n-1$ degrees of freedom.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a critical value\n",
    "\n",
    "With a test statistic and a sample in hand, Maia can now compute the probability (under the null) of drawing a sample with size $n$ that has a mean at least as large as that of her sample.  The last thing she needs to decide is the *critical value* of the test statistic, which defines the threshold level of the test statistic at which the null hypothesis should be rejected.  We typically set our critical value such that the probability density on the extreme side of the test statistic distibution is equal to a particular level, which defines the *significance level* of the test.  \n",
    "\n",
    "This is illustrated in the following code, which graphs a t-distribution, a selected significance level, and its associated critical value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value = 1.725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7f626f951e10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import t \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "df=20\n",
    "siglev = 0.05\n",
    "cv = t.ppf(1-siglev,df)\n",
    "tgrid = np.arange(t.ppf(0.001,df),t.ppf(0.999,df),0.01)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(tgrid, t.pdf(tgrid, df),'r-', lw=2, alpha=0.6, label='t pdf')\n",
    "\n",
    "\n",
    "print(\"Critical value = %5.3f\" % cv)\n",
    "tgridcrit = tgrid[tgrid>cv]\n",
    "ax.fill_between(tgridcrit, 0, t.pdf(tgridcrit,df), facecolor='green', interpolate=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors to Consider in Determining Significance Level\n",
    "\n",
    "\n",
    "* The significance level determines how often Maia will accidentally reject a true null (Type 1 Error)\n",
    "* Setting the significance level (critical value) too low (high) risks failing to reject a false null hypothesis (Type 2 Error)  \n",
    "\n",
    "Let's consider two scenarios: \n",
    "\n",
    "1. Maia's true mean commute time is $\\mu=29$ with variance $\\sigma^2=32$ and she collects data on her commute $n=20$ days.  \n",
    "\n",
    "2. Maia's true mean commute time is $\\mu=31$ with variance $\\sigma^2=32$ and she collects data on her commute $n=20$ days.\n",
    "\n",
    "Let's simulate each of these scenarios a bunch of times and see how different decision rules work out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results \n",
      "\n",
      "mu=29.00, siglev=0.050 || Do not reject=4960, Reject=40 \n",
      "mu=29.00, siglev=0.025 || Do not reject=4980, Reject=20 \n",
      "mu=29.00, siglev=0.010 || Do not reject=4995, Reject=5 \n",
      "mu=31.00, siglev=0.050 || Do not reject=4035, Reject=965 \n",
      "mu=31.00, siglev=0.025 || Do not reject=4409, Reject=591 \n",
      "mu=31.00, siglev=0.010 || Do not reject=4710, Reject=290 \n",
      "\n",
      "**************************\n",
      "\n",
      "Precision vs. Recall \n",
      "\n",
      "siglev = 0.050 || Recall = 0.960, Precision = 0.193\n",
      "siglev = 0.025 || Recall = 0.967, Precision = 0.118\n",
      "siglev = 0.010 || Recall = 0.983, Precision = 0.058\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "from scipy.stats import norm \n",
    "nsim = 5000 \n",
    "mu1 = 29\n",
    "mu2 = 31 \n",
    "mutest = 30\n",
    "s2 = 32 \n",
    "n=20\n",
    "df=n-1 \n",
    "\n",
    "# Let's define the t-test: stats.norm has an appropriate test we can use, but we'll do it manually here for the sake\n",
    "# of illustration \n",
    "def ttest(sample,siglev,mut):\n",
    "    xbar = np.mean(sample)\n",
    "    dfsamp = len(sample)-1\n",
    "    sest = np.sqrt(np.var(sample-xbar,ddof=1))\n",
    "    tstat = np.sqrt(len(sample))*(xbar - mut)/sest\n",
    "    tsig = 1-t.cdf(tstat,dfsamp)\n",
    "    rejectnull = (tsig<siglev) \n",
    "    return(rejectnull)\n",
    "    \n",
    "# Let's create our simulated data samples \n",
    "np.random.seed(17)\n",
    "samp1 = norm.rvs(loc=mu1,scale=np.sqrt(s2),size=(n,nsim))\n",
    "samp2 = norm.rvs(loc=mu2,scale=np.sqrt(s2),size=(n,nsim))\n",
    "\n",
    "# For each test, let's run a level at 5%, 2.5%, and 1% significance \n",
    "# In each case, we'll count how many times the test rejects the null hypothesis \n",
    "res1s5 = [ttest(samp1[...,x],siglev=0.05,mut=mutest) for x in range(nsim)]\n",
    "res1s25 = [ttest(samp1[...,x],siglev=0.025,mut=mutest) for x in range(nsim)]\n",
    "res1s1 = [ttest(samp1[...,x],siglev=0.01,mut=mutest) for x in range(nsim)]    \n",
    "\n",
    "res2s5 = [ttest(samp2[...,x],siglev=0.05,mut=mutest) for x in range(nsim)]\n",
    "res2s25 = [ttest(samp2[...,x],siglev=0.025,mut=mutest) for x in range(nsim)]\n",
    "res2s1 = [ttest(samp2[...,x],siglev=0.01,mut=mutest) for x in range(nsim)] \n",
    "\n",
    "\n",
    "def nreject(results):\n",
    "    return(len([x for x in results if x]))\n",
    "\n",
    "def nnoreject(results):\n",
    "    return(len([x for x in results if not x]))\n",
    "\n",
    "\n",
    "print(\"Test results \\n\")\n",
    "print(\"mu=%5.2f, siglev=%5.3f || Do not reject=%d, Reject=%d \" % (mu1,0.05,nnoreject(res1s5),nreject(res1s5)))\n",
    "print(\"mu=%5.2f, siglev=%5.3f || Do not reject=%d, Reject=%d \" % (mu1,0.025,nnoreject(res1s25),nreject(res1s25)))\n",
    "print(\"mu=%5.2f, siglev=%5.3f || Do not reject=%d, Reject=%d \" % (mu1,0.01,nnoreject(res1s1),nreject(res1s1)))\n",
    "\n",
    "print(\"mu=%5.2f, siglev=%5.3f || Do not reject=%d, Reject=%d \" % (mu2,0.05,nnoreject(res2s5),nreject(res2s5)))\n",
    "print(\"mu=%5.2f, siglev=%5.3f || Do not reject=%d, Reject=%d \" % (mu2,0.025,nnoreject(res2s25),nreject(res2s25)))\n",
    "print(\"mu=%5.2f, siglev=%5.3f || Do not reject=%d, Reject=%d \" % (mu2,0.01,nnoreject(res2s1),nreject(res2s1)))\n",
    "print(\"\\n**************************\\n\")\n",
    "    \n",
    "print(\"Precision vs. Recall \\n\")\n",
    "print(\"siglev = %5.3f || Recall = %5.3f, Precision = %5.3f\" % (0.05, \n",
    "                                                               nreject(res2s5)/(nreject(res2s5) + nreject(res1s5)),\n",
    "                                                               nreject(res2s5)/(nreject(res2s5) + nnoreject(res2s5))))\n",
    "\n",
    "print(\"siglev = %5.3f || Recall = %5.3f, Precision = %5.3f\" % (0.025, \n",
    "                                                               nreject(res2s25)/(nreject(res2s25) + nreject(res1s25)),\n",
    "                                                               nreject(res2s25)/(nreject(res2s25) + nnoreject(res2s25))))\n",
    "\n",
    "\n",
    "print(\"siglev = %5.3f || Recall = %5.3f, Precision = %5.3f\" % (0.01, \n",
    "                                                               nreject(res2s1)/(nreject(res2s1) + nreject(res1s1)),\n",
    "                                                               nreject(res2s1)/(nreject(res2s1) + nnoreject(res2s1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall\n",
    "\n",
    "Inspection of the above results reveals a trade-off that Maia faces in setting the significance level of her test.  Setting a higher significance level increases the likelihood that she rejects her null hypothesis both when she should and when she should not.  \n",
    "\n",
    "Two common measures of test performance are recall and precision.  Precision measures how often Maia's test rejects the null when it should.  Recall measures how often the test is correct when it does reject the null.   \n",
    "* Recall=$\\frac{\\text{Correctly Rejected Null}}{\\text{Correctly Rejected Null} + \\text{Incorrectly Rejected Null}}$\n",
    "* Precision=$\\frac{\\text{Correctly Rejected Null}}{\\text{Correctly Rejected Null} + \\text{Incorrectly Failed to Reject Null}}$ \n",
    "\n",
    "As the values above illustrate, higher levels of significance increase the precision of Maia's test (she's more likely to reject the null hypothesis when she should) but decrease its recall (she's more likely to reject the null by mistake). \n",
    "\n",
    "* Whether precision or recall is more important depends on the specific context and the priorities of the person designing the test\n",
    "* We can visualize the tradeoff between precision and recall by plotting them for various levels of significance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions and Extensions\n",
    "\n",
    "In order for the t-test procedure described above to be *exactly* correct, the difference between the estimator (the sample mean) and the parameter of interest must be normally distributed.  \n",
    "\n",
    "When this difference is non-normally distributed, the t-test is still asymptotically valid as long as the data generating process satisfies the necessary conditions for one of several central limit theorems.  \n",
    "\n",
    "The t-test applies to almost any case where the model admits a statistic that is equal to the sum of (1) a true parameter and (2) an error term.  \n",
    "\n",
    "* For example, under the standard assumptions that validate Ordinary Least Squares (OLS) regression, the OLS estimator is equal to $\\hat{\\beta}_{OLS} = \\beta + (X'X)^{-1}X'\\varepsilon$ \n",
    "\n",
    "The t-test can also be generalized to test null hypotheses covering more than one parameter of a model (F-test)\n",
    "\n",
    "Here's a more practical application: OLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   MEDV   R-squared:                       0.849\n",
      "Model:                            OLS   Adj. R-squared:                  0.848\n",
      "Method:                 Least Squares   F-statistic:                     938.4\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):          1.42e-205\n",
      "Time:                        08:12:44   Log-Likelihood:                -1855.1\n",
      "No. Observations:                 506   AIC:                             3716.\n",
      "Df Residuals:                     503   BIC:                             3729.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "CRIM          -0.3826      0.074     -5.187      0.000      -0.528      -0.238\n",
      "NOX           62.5178      1.803     34.670      0.000      58.975      66.061\n",
      "INDUS         -1.0478      0.090    -11.646      0.000      -1.225      -0.871\n",
      "==============================================================================\n",
      "Omnibus:                       63.238   Durbin-Watson:                   0.622\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               96.073\n",
      "Skew:                           0.828   Prob(JB):                     1.37e-21\n",
      "Kurtosis:                       4.348   Cond. No.                         63.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# Let's load a \"real\" dataset and run some regressions \n",
    "from sklearn import datasets \n",
    "import pandas as pd \n",
    "import statsmodels.api as smod \n",
    "boston = datasets.load_boston()\n",
    "\n",
    "print(boston.DESCR)\n",
    "\n",
    "\n",
    "# Let's do a simple regression of crime, polution, and business density on median property values \n",
    "indvar = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "depvar = pd.DataFrame(boston.target, columns=[\"MEDV\"])\n",
    "olsmod = smod.OLS(depvar['MEDV'],indvar[['CRIM','NOX','INDUS']]).fit().get_robustcov_results() \n",
    "\n",
    "print(olsmod.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference\n",
    "\n",
    "Two main paradigms for thinking about statistical inference\n",
    "\n",
    "* Frequentist approach: Learning about fixed parameter values based on a random data.\n",
    "* Bayesian approach: Learning about random (unknown) parameter values based on a fixed data\n",
    "\n",
    "The Bayesian approach posits a *prior* distribution of the parameters of the model and updates this distribution based on observed data to form a *posterior* that takes the information content of the data into account.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Review of Bayes' Theorem\n",
    "\n",
    "Let's begin with two facts from probability theory\n",
    "\n",
    "1. For any two events $A$ and $B$, $$P(A|B)P(B)=P(A\\cup B)$$\n",
    "\n",
    "1. For any two events $A$ and $B$, $$P(B) = P(B|A)P(A) + P(B|A')P(A')$$  \n",
    "\n",
    "Since $A$ and $B$ are arbitrarily positioned, together these two facts imply \n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}=\\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A')P(A')}$$ \n",
    "\n",
    "* Heuristically, this says that the probability that $A$ is true given that $B$ is true is equal to the probability that both are true divided by the probability that $B$ is true (regardless of whether A is true or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operationalizing Bayes' Theorem\n",
    "\n",
    "Returning to the commute time problem, Maia can treat her mean commute time as a random variable about which she can use data to update her beliefs\n",
    "\n",
    "$$ f(\\mu|{\\bf x}) = \\frac{f({\\bf x} | \\mu) f(\\mu)}{\\int f({\\bf x} | \\mu) f(\\mu) d\\mu }$$\n",
    "\n",
    "Let's break apart the components of this expression:\n",
    "\n",
    "* $f(\\mu)$ is Maia's *prior* on the distribution of $\\mu$.  Before Maia begins working at her new job and begins actually collecting data on her commute, we posit that she has some initial beliefs on the probabilities that her actual mean commute time $\\mu$ is equal a given value.  These initial beliefs are typically an assumption or are based on another source of information\n",
    "\n",
    "* $f({\\bf x} | \\mu)$ is based on the model Maia uses to describe the data generating process for her sample.  Recalling that Maia's model specified that $X \\overset{i.i.d.}{\\sim}N(\\mu,\\sigma^2)$, given a fixed value of $\\sigma^2$, it follows that \n",
    "\n",
    "$$ f({\\bf x} | \\mu) = \\prod_{i=1}^n \\phi\\left(\\frac{x_i - \\mu}{\\sigma} \\right)$$\n",
    "\n",
    "where $\\phi$ is the standard normal probability density function.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjugate priors\n",
    "\n",
    "Since our goal is ultimately utilize the posterior distribution $f(\\mu|{\\bf x})$ we develop for other purposes, we'll often find it useful or necessary to choose a prior that produces a posterior distribution that's easy to work with.  \n",
    "\n",
    "*Conjugate priors* are distributions that produce posterior distributions in the same functional family\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Normal (known variance)\n",
    "* Normal / Inverse-Gamma - t-distribution\n",
    "* Bernoulli\n",
    "* Poisson - Negative Binomial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal (known variance prior)\n",
    "\n",
    "Let's assume that Maia's prior is that $\\mu \\sim N(m_0,v_0^2)$.  Given the expression for $ f({\\bf x} | \\mu)$ derived from our model (above), one can show that \n",
    "\n",
    "$$ \\mu | {\\bf x} \\sim N\\left( \\frac{\\frac{\\sigma^2}{n}m_0 + v_0^2 \\bar{x}}{\\frac{\\sigma^2}{n}  + v_0^2},\\frac{\\frac{ \\sigma^2}{n} v_0^2}{\\frac{\\sigma^2}{n} +v_0^2} \\right)$$\n",
    "\n",
    "The posterior mean is just a weighted average of the prior mean and the sample mean (the test statistic!).  \n",
    "\n",
    "Each component is weighted based on its reliability - the more variable a component is, the less it factors into the posterior\n",
    "\n",
    "Let's return to the previous samples we generated.  Suppose Maia's initial prior is $\\mu \\sim N(30,50)$.  Let's also assume for simplicity that she knows that $\\sigma^2=32$ with certainty.  We'll look at what happens when she updates based on a sample drawn where $x_i \\sim N(31,32)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior mean = 30.000 || Prior variance = 50.000\n",
      "Data mean = 31.201 || Data mean variance = 1.600\n",
      "Posterior mean = 31.164 || Posterior variance = 1.550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6266fbe240>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The first thing we're going to do is look at how a prior and data sample are combined into a posterior distribution \n",
    "from scipy.stats import gaussian_kde \n",
    "# Let's set the prior/known parameters \n",
    "m0 = 30\n",
    "v02 = 50\n",
    "s2 = 32\n",
    "\n",
    "# Let's get data from one of our samples \n",
    "samp21 = samp2[:,0]\n",
    "xbar = np.mean(samp21)\n",
    "n = len(samp21)\n",
    "s2hat = s2/n \n",
    "\n",
    "# Let's get the density of the sample\n",
    "sdensity = gaussian_kde(samp21) \n",
    "sdensity.set_bandwidth(bw_method=sdensity.factor / 0.5)\n",
    "# Now let's form the posterior \n",
    "mpost = (s2hat * m0 + v02 *xbar)/(s2hat + v02)\n",
    "v12 = s2hat*v02/(s2hat + v02)\n",
    "\n",
    "print(\"Prior mean = %5.3f || Prior variance = %5.3f\" % (m0,v02))\n",
    "print(\"Data mean = %5.3f || Data mean variance = %5.3f\" % (xbar,s2hat))\n",
    "print(\"Posterior mean = %5.3f || Posterior variance = %5.3f\" % (mpost,v12))\n",
    "\n",
    "\n",
    "\n",
    "xgrid = np.arange(norm.ppf(0.01,loc=m0,scale=np.sqrt(v02)),norm.ppf(0.99,loc=m0,scale=np.sqrt(v02)),0.01)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(xgrid, norm.pdf(xgrid,loc=m0,scale=np.sqrt(v02)),'r-', lw=2, alpha=0.6, label='prior')\n",
    "ax.plot(xgrid, sdensity(xgrid),'b-', lw=2, alpha=0.6, label='data')\n",
    "ax.plot(xgrid, norm.pdf(xgrid,loc=mpost,scale=np.sqrt(v12)),'g-', lw=2, alpha=0.6, label='posterior')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles,labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Bayesian\" Hypothesis Testing\n",
    "\n",
    "A straightforward decision rule that Maia can use to decide whether to look for a new job or not is to quit if the posterior mean is greater than 30.   \n",
    "\n",
    "Maia can check how often she expects her decision criterion to be correct/incorrect by sampling from the posterior distribution of the parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maia's predicted probability that quitting is the right move = 0.825\n",
      "Maia's predicted probability that quitting is the right move under diffuse prior = 0.830\n"
     ]
    }
   ],
   "source": [
    "# Let's estimate Maia's expected probability of making the correct decision (quitting)\n",
    "ndraws = 100000\n",
    "postsamp = norm.rvs(loc=mpost,scale=np.sqrt(v12),size=(ndraws))\n",
    "ngt30 = len(postsamp[postsamp>=30])\n",
    "pctcorrect = ngt30/ndraws \n",
    "print(\"Maia's predicted probability that quitting is the right move = %5.3f\" % pctcorrect)\n",
    "\n",
    "# Let's do the same thing now with a diffuse prior \n",
    "v02diffuse = 10000\n",
    "mpost2 = (s2hat * m0 + v02diffuse *xbar)/(s2hat + v02diffuse)\n",
    "vpost2 = s2hat*v02diffuse/(s2hat + v02diffuse)\n",
    "postsamp2 = norm.rvs(loc=mpost2,scale=np.sqrt(vpost2),size=(ndraws))\n",
    "ngt30 = len(postsamp2[postsamp2>=30])\n",
    "pctcorrect = ngt30/ndraws \n",
    "print(\"Maia's predicted probability that quitting is the right move under diffuse prior = %5.3f\" % pctcorrect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Posterior Predictives\n",
    "\n",
    "* In her previous work with hypothesis testing, Maia was able to estimate the distribution of her (sample) mean commute time under the assumption that a fixed null hypothesis was correct.  \n",
    "\n",
    "* Bayesian inference allows her to conduct a similar exercise - estimating the distribution of her (sample) mean commute time under the assumption that model parameters follow a particular distribution\n",
    "\n",
    "* Under Maia's current model with prior, $\\mu \\sim N(m_0,v_0^2)$, the posterior predictive distribution of the mean of a sample of size $n$ is equal to \n",
    "\n",
    "$$ \\tilde{\\bar{x}} \\sim N\\left(\\frac{\\hat{\\sigma}^2 m_0 + v_0^2 \\bar{x}}{\\hat{\\sigma}^2  + v_0^2}, \\frac{\\hat{\\sigma}^2 v_0^2}{\\hat{\\sigma}^2 +v_0^2} + \\hat{\\sigma}^2 \\right)$$\n",
    "\n",
    "The Bayesian approach factors uncertainty in the null hypothesis.  If $v_0=0$, confidence intervals about sample statistics generated by posterior predictive sampling align with the confidence intervals, critical values, etc. generated from an analogous null hypothesis in a hypothesis test.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "* Posterior predictive distributions can be used to forecast or simulate additional data \n",
    "* Yesterday's posterior can be today's prior in order to smoothly incorporate new information into a model \n",
    "* Non-conjugate distributions can be utilized with Markov Chain Monte Carlo (MCMC) methods (pymc3 module) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"proof1\"></a> \n",
    "#### Proof 1\n",
    "\n",
    "Let $e_i = x_i - \\bar{x}$.  Under our model, we can substitute for $x_i$ and $\\bar{x}$, which yields \n",
    "\n",
    "$e_i = (\\mu + \\varepsilon_i) -(\\mu + \\frac{1}{n} \\sum_{j=1}^n \\varepsilon_j) = \\frac{n-1}{n} \\varepsilon_i + \\frac{1}{n} \\sum_{j\\neq i} \\varepsilon_j$\n",
    "\n",
    "Squaring this gives\n",
    "\n",
    "$e_i^2 = \\frac{1}{n^2}((n-1)\\varepsilon_i + \\sum_{j\\neq i} \\varepsilon_j)^2 = \\left(\\frac{n-1}{n} \\right)^2 \\varepsilon_i^2 + \\frac{1}{n^2} \\sum_{j\\neq i} \\varepsilon_j^2 + \\text{other terms involving interactions between $\\varepsilon_j\\varepsilon_k, j \\neq k$}$  \n",
    "\n",
    "Hence,\n",
    "\n",
    "\n",
    "$s^2 = \\frac{1}{n-1} \\sum_{i=1}^n e_i^2$\n",
    "\n",
    "$ = \\frac{1}{n-1} \\sum_{i=1}^n \\left(\\frac{(n-1)^2}{n^2} + \\frac{n-1}{n^2} \\varepsilon_i^2\\right)  + \\text{interaction terms}$ \n",
    "\n",
    "$= \\frac{1}{n-1} \\sum_{i=1}^n \\frac{n-1}{n^2}(n-1+1)\\varepsilon_i^2 + \\text{interaction terms}$\n",
    "\n",
    "$= \\frac{1}{n} \\sum_{i=1}^n \\varepsilon_i^2 + \\text{interaction terms}$    \n",
    "\n",
    "Under our model $\\varepsilon_i \\overset{i.i.d.}{\\sim}N(0,\\sigma^2)$, so the expected value of the expression above is exactly equal to $\\sigma^2$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"proof2\"></a>\n",
    "##### Proofs 2 and 3 \n",
    "Proofs 2 and 3 are standard in statistics textbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
